<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Daniele Grattarola</title>
    <description>A blog about AI and other interesting stuff.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="nathanrooy.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 07 Jun 2018 16:23:38 +0200</pubDate>
    <lastBuildDate>Thu, 07 Jun 2018 16:23:38 +0200</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
      
    
    <item>
        <title>Graph Embeddings on Constant-Curvature Manifolds for Change Detection</title>
        <description>&lt;p&gt;&lt;img src=&quot;http://localhost:4000/images/2018-06-07/embeddings_plot.png&quot; alt=&quot;Embeddings&quot; class=&quot;full-width&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When considering relational problems, the temporal dimension is often crucial to understand whether the process behind the relational graph is evolving, and how; think how often people follow and unfollow each other on Instagram, how the type of content in one’s posts may change over time, and how all of these aspects are echoed throughout the network, interacting with one another in complex ways.&lt;/p&gt;

&lt;p&gt;While most works that apply deep learning to temporal networks are focused on the evolution of the graph at the node or edge level, it is extremely interesting to study a graph-based process from a global perspective, at the graph level, to detect trends and changes in the process itself.
&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;This post is a simplified version of &lt;a href=&quot;https://arxiv.org/abs/1805.06299&quot;&gt;this paper&lt;/a&gt;, so you might want to have a look at either one before reading the other.&lt;/p&gt;

&lt;h2 id=&quot;be-the-change-you-want-to-see-in-the-process&quot;&gt;Be the change you want to see in the process&lt;/h2&gt;

&lt;p&gt;We consider a process generating a stream of graphs (e.g. hourly snapshots of a power supply grid), and we make the assumption of having two &lt;em&gt;states&lt;/em&gt;: a nominal regime (when the grid is stable) and a non-nominal regime (when there’s about to be a blackout). We know what the graphs look like in the nominal state, and we can use a dataset of nominal graphs to train our models, but we cannot know what the non-nominal state will look like: the goal is to discriminate between the two regimes, regardless.&lt;br /&gt;
If we consider this as a one-class classification problem, then we have &lt;em&gt;anomaly detection&lt;/em&gt;; if we take into account the temporal dimension, then the task is to detect whether the process has permanently shifted to non-nominal, and we have the &lt;em&gt;change detection&lt;/em&gt; problem, on which we focus here.&lt;/p&gt;

&lt;p&gt;Change detection can be easily formulated in statistical terms by considering two unknown nominal and non-nominal distributions driving a process, and running tests that can tell us whether the process is operating in one regime or the other.
When dealing with graphs, however, things get a bit more complicated.&lt;br /&gt;
While detecting changes in stationarity directly on the graph space is possible, it is also analytically complex. In particular, since most graph distances are non-metric, the resulting non-Euclidean geometry of the space is often unknown, making it quite harder to apply standard statistical tools. Even if we consider better-behaved metric distances, the computational complexity of dealing with the graph space is often intractable.&lt;br /&gt;
A common approach to circumvent this issue, then, is to represent the graphs in a simpler space via graph embedding.&lt;/p&gt;

&lt;h2 id=&quot;enter-representation-learning&quot;&gt;Enter representation learning&lt;/h2&gt;

&lt;p&gt;The key idea behind our approach is the following: we train a &lt;a href=&quot;https://arxiv.org/abs/1802.03480&quot;&gt;graph autoencoder&lt;/a&gt; to extract a representation of the graphs on a somewhat simpler space, so that all the well known statistical tools for change detection become available for us to use.&lt;br /&gt;
However, since we already noted that graphs do not naturally lie in Euclidean spaces, we can look for a better embedding space, which can intrinsically represent some of the non-trivial properties of the space of graphs.&lt;/p&gt;

&lt;p&gt;Since non-Euclidean geometry is basically any relaxation of the Euclidean one, we can freely pick our favorite non-Euclidean embedding space, where a desirable property of this space is to have computationally tractable metric distances, and a simple analytical form to make calculations easier.&lt;/p&gt;

&lt;p&gt;A good family of spaces that reflect these characteristics is the family of &lt;em&gt;constant curvature Riemannian manifolds&lt;/em&gt; (CCMs): hyperspheres and hyperboloids.&lt;/p&gt;

&lt;h2 id=&quot;algorithm-overview&quot;&gt;Algorithm overview&lt;/h2&gt;
&lt;p&gt;Let’s take a global view of the algorithm before diving into the details. The important steps are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Take a sequence of nominal graphs&lt;/li&gt;
  &lt;li&gt;Train the AE to embed the graphs on a CCM&lt;/li&gt;
  &lt;li&gt;Take a stream of graphs that &lt;em&gt;may&lt;/em&gt; eventually change to the non-nominal regime&lt;/li&gt;
  &lt;li&gt;Use the encoder to map the stream to the CCM&lt;/li&gt;
  &lt;li&gt;Run a change detection test on the CCM to identify changes the stream&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The sequence of graphs in step 1 is also mapped to the CCM and used to configure the change detection test (more on that later).&lt;br /&gt;
In a real-world scenario, step 3 is the stream of graphs observed by the algorithm after being deployed, where we have no information on the real state of the system. To test our methodology, however, we consider a stream of graphs with a known change point, and use it as ground truth to evaluate performance.&lt;/p&gt;

&lt;h2 id=&quot;adversarial-graph-autoencoder&quot;&gt;Adversarial Graph Autoencoder&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/images/2018-06-07/scheme.png&quot; alt=&quot;Full architecture&quot; class=&quot;full-width&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Building an autoencoder that maps the data distribution to a CCM requires imposing some sort of constraint on the latent space of the network, either by explicitly constraining the representation (e.g. by projecting the embeddings onto the CCM), or by letting the AE learn a representation on a CCM autonomously.&lt;br /&gt;
In our approach, we choose a mix of the two solutions: first, we let the AE learn a representation that lies as close as possible to the CCM, and then (once we’re sure that the projection will not introduce too much bias) we rectify the embeddings by clipping them onto the surface of the CCM.&lt;/p&gt;

&lt;p&gt;To impose an implicit constraint on the representation, we resort to the &lt;a href=&quot;https://arxiv.org/abs/1511.05644&quot;&gt;adversarial autoencoder&lt;/a&gt; framework, where we take a more GAN-like approach and only use the encoder as the generator, ignoring the decoder. 
We define a prior distribution with support on the CCM, by mapping an equivalent Euclidean distribution onto the CCM via the &lt;a href=&quot;https://en.wikipedia.org/wiki/Exponential_map_(Riemannian_geometry)&quot;&gt;Riemannian exponential map&lt;/a&gt;, and we then match the aggregated posterior of the AE with this prior.&lt;/p&gt;

&lt;p&gt;This has the twofold effect of 1) implicitly defining the embedding surface that the AE has to learn in order to confuse the discriminator network, and 2) making the AE use all of the latent space uniformly.&lt;/p&gt;

&lt;p&gt;Using this &lt;em&gt;CCM prior&lt;/em&gt; is the simplest modification to the standard AAE framework that we can make to impose the geometric constraint on the latent space, but in general we may want to drop the statistical conditioning of the posterior and find ways to let the AE learn the representation on the CCM freely. 
To do this, we introduce an analytical &lt;em&gt;geometric discriminator&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;geometric-discriminator&quot;&gt;Geometric discriminator&lt;/h2&gt;

&lt;p&gt;If we ignore the statistical conditioning of the AE’s posterior, we are left with the task of simply placing the embeddings onto the CCM. 
Since we already defined a training framework for the AE that relies on adversarial learning, we can stick to this methodology and slightly change it to fit our new, relaxed requirements.&lt;/p&gt;

&lt;p&gt;The key idea behind adversarial networks is that both the generator and the discriminator strive to be better against each other, but what if the discriminator were already the best possible discriminator that may ever exist? What if the discriminator only had to compute a known classification function, without learning it? &lt;br /&gt;
This is the idea behind the geometric discriminator.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/images/2018-06-07/geom_critic.png&quot; alt=&quot;Geometric critic&quot; class=&quot;full-width&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We consider a function &lt;script type=&quot;math/tex&quot;&gt;D_\kappa(\vec z)&lt;/script&gt; depending on the curvature &lt;script type=&quot;math/tex&quot;&gt;\kappa \ne 0&lt;/script&gt; of the CCM, where:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_{\kappa}(\vec z) = 
    \mathrm{exp}\left(\cfrac{-\big( \langle \vec z, \vec z \rangle - \frac{1}{\kappa} \big)^2}{2\varsigma^2}\right)&lt;/script&gt;

&lt;p&gt;which intuitively takes samples &lt;script type=&quot;math/tex&quot;&gt;\vec z&lt;/script&gt; from the latent space and computes their &lt;em&gt;membership&lt;/em&gt; to the CCM.&lt;br /&gt;
When optimized to fool the geometric discriminator, the AE will learn to place its codes on the CCM, while at the same time being free to choose the best latent representation to optimize the reconstruction loss. &lt;br /&gt;
In principle, we could argue that this formulation is equivalent to imposing a regularization term during the optimization of the AE, but experimental results showed us that separating the reconstruction and regularization phases yielded more stable and more effective results.&lt;/p&gt;

&lt;h2 id=&quot;change-detection-tests-for-ccms&quot;&gt;Change detection tests for CCMs&lt;/h2&gt;

&lt;p&gt;Having defined a way to represent our graph stream on a manifold with better geometrical properties than the simple Euclidean space, we now have to run the change detection test on the embedded stream of graphs.&lt;/p&gt;

&lt;p&gt;Our change detection test is built upon the CUmulative SUMs algorithm (dating back to the 50’s), which basically consists in monitoring a generic stream of points by taking sequential windows of them, computing some &lt;em&gt;local statistic&lt;/em&gt; across each window, and summing up the local statistics in a &lt;em&gt;global accumulator&lt;/em&gt;.&lt;br /&gt;
The algorithm raises an &lt;em&gt;alarm&lt;/em&gt; every time that the accumulator exceeds a particular &lt;em&gt;detection threshold&lt;/em&gt; (and the accumulator is reset to 0 after that).&lt;br /&gt;
Using the (embedded) training graphs, we set the threshold such that the probability of the accumulator exceeding the threshold in the nominal regime is a given value &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;.
Once the threshold is set, we monitor the operational stream, knowing that any detection rate above &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt; will likely be associated to a change in the process.&lt;/p&gt;

&lt;p&gt;Since the detection threshold is set by statistically studying the accumulator, we can estimate it by knowing the distribution of the local statistics that make up the accumulator. To do this, we consider as local statistic the Mahalanobis distance between the mean of the training samples and the mean of the operational window, which thanks to the central limit theorem has a known distribution.&lt;/p&gt;

&lt;p&gt;So now we have outlined a change detection test for a generic stream, but where does non-Euclidean geometry come into play? In the paper we propose two different approaches to exploit it, both consisting in picking different ways to build the stream that is monitored by the CUSUM test.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Distance-based CDT (D-CDT)&lt;/strong&gt;: we take the training stream of nominal graphs and compute the &lt;em&gt;Fréchet mean&lt;/em&gt; of the points on the CCM; for each embedding in the operational stream, then, we compute the geodesic distance between the mean and the embedding itself. This results in the stream of embeddings being mapped to a stream of distances, which we then monitor with the CUSUM-based algorithm described above.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Riemannian CLT-based CDT (R-CDT)&lt;/strong&gt;: here we take a slightly more geometrical approach, where instead of considering the Euclidean CLT we take the &lt;em&gt;Riemannian CLT&lt;/em&gt; proposed by &lt;a href=&quot;https://arxiv.org/abs/1801.00898&quot;&gt;Bhattacharya and Lin&lt;/a&gt;, which works directly for points on a Riemannian manifold and modifies the Mahalanobis distance to deal with the non-Euclidean geometry. In short, the approach considers a stream of points obtained by mapping the CCM-embedded graphs to a tangent plane using the Riemannian log-map, and computes the detection threshold using the modified local statistic.&lt;/p&gt;

&lt;p&gt;This might seem like a lot to deal with, but worry not: &lt;a href=&quot;https://github.com/dan-zam/cdg&quot;&gt;there’s a public repo to do this stuff for you&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;combined-ccms&quot;&gt;Combined CCMs&lt;/h2&gt;

&lt;p&gt;As final touch, some considerations on what CCM to pick for embedding the graph stream.&lt;br /&gt;
In general, there are infinite curvatures to choose from, but we really only need to worry about the sign of the curvature, because that’s what determines whether the space is spherical or hyperbolic (or even Euclidean, if we set the curvature to 0).&lt;/p&gt;

&lt;p&gt;Different problems may benefit from different geometries, depending on the task-specific distances that determine the geometry of the original space of graphs (for instance, MNIST - yes, images are graphs too - &lt;a href=&quot;https://arxiv.org/abs/1804.00891&quot;&gt;has been shown&lt;/a&gt; to do well on spherical manifolds).&lt;br /&gt;
But how can know whether a sphere or an hyperboloid is the best fit for a problem? How do we know that the Euclidean space isn’t actually the best one? 
In principle, we could train an AE for each manifold and test the performance of the algorithm, but what if we don’t have enough data to get reliable results? What if have too much, and training is expensive?&lt;/p&gt;

&lt;p&gt;A fairly trivial, but effective solution is to not pick just &lt;em&gt;one&lt;/em&gt; manifold (pfffft!), but pick ALL of them at the same time and learn a joint representation.
Formally, we consider an &lt;em&gt;ensemble manifold&lt;/em&gt; as the Cartesian product of different CCMs, and slightly adapt our architecture accordingly (essentially we take the relevant building blocks of our pipeline and put them in parallel, with some shared convolutions here and there - check Section 3.3 of the paper for details).&lt;br /&gt;
Since the actual values of the curvatures are less important than their signs, we can take only three CCMs to build our ensemble: a spherical CCM of curvature 1, an hyperbolic CCM of curvature -1, and an Euclidean CCM of curvature 0.&lt;/p&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;p&gt;To validate our methodology, we ran experiments in two different settings: a synthetic, controlled one, and a real-world scenario of epileptic seizure detection.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/images/2018-06-07/delaunay.png&quot; alt=&quot;Delaunay triangulations&quot; class=&quot;full-width&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For the synthetic scenario, we considered graphs obtained as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Delaunay_triangulation&quot;&gt;Delaunay triangulations&lt;/a&gt; of points in a plane (pictured above), where we controlled the change in the stream by adding perturbations of different intensity to the support points of the graphs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/images/2018-06-07/ieeg.png&quot; alt=&quot;iEEG data&quot; class=&quot;full-width&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For the seizure detection scenario, we considered Kaggle’s &lt;a href=&quot;https://www.kaggle.com/c/seizure-detection&quot;&gt;UPenn and Mayo Clinic’s Seizure Detection Challenge&lt;/a&gt; and &lt;a href=&quot;https://www.kaggle.com/c/seizure-prediction&quot;&gt;American Epilepsy Society Seizure Prediction Challenge&lt;/a&gt; datasets, composed of iEEG signals for different human and dog patients, with a different number of electrodes attached to each patient resulting in different multivariate signals. &lt;br /&gt;
The signals are provided in 1-second i.i.d. clips of different classes (the nominal &lt;em&gt;interictal&lt;/em&gt; states where the patient is fine, and the non-nominal &lt;em&gt;ictal&lt;/em&gt; states where the patient is having a seizure), for each patient, and the original task of the challenge is to classify the clips correctly.&lt;br /&gt;
Since a common approach in neuroscience to deal with iEEG data is to build &lt;a href=&quot;https://www.frontiersin.org/articles/10.3389/fnsys.2015.00175/full&quot;&gt;functional connectivity networks&lt;/a&gt; to study the relationships between different areas of the brain, especially during rare episodes like seizures, this task was the perfect playground to test our complex methodology. 
We converted each 1-second clip to a graph using Pearson’s correlation as functional connectivity measure, and the topmost 4 wavelet coefficients of each signal as node attributes.&lt;br /&gt;
To simulate the graph streams, we used the labeled training data from the challenges to build the training and operational streams for each patient, where a change in the stream simply consisted in sampling graphs from the ictal class instead of the nominal.&lt;/p&gt;

&lt;h3 id=&quot;results-in-short&quot;&gt;Results in short&lt;/h3&gt;

&lt;p&gt;The important aspects that emerged after the experimental phase are the following:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The ensemble of CCM, with the geometric critic, and R-CDT is the most effective change detection architecture among the ones tested (which included a purely Euclidean AE and a non-neural baseline for embedding graphs). This highlights how the AE is encoding different, yet useful information on the different CCMs;&lt;/li&gt;
  &lt;li&gt;Exclusively spherical and hyperbolic AEs are relevant in some rare cases;&lt;/li&gt;
  &lt;li&gt;Using the geometric discriminator often yields a better performance w.r.t. the standard discriminator, while reducing the number of trainable parameters by up to 13%;&lt;/li&gt;
  &lt;li&gt;We are able to detect extremely small changes (in the order of &lt;script type=&quot;math/tex&quot;&gt;10^{-3}&lt;/script&gt;) in the distribution driving the Delaunay stream;&lt;/li&gt;
  &lt;li&gt;We are able to detect changes in both the iEEG detection and prediction challenges with good accuracy in most cases, except for a couple of patients for which we see an accuracy drop;&lt;/li&gt;
  &lt;li&gt;The model does not require excessive hyperparameter tuning in order to perform well; a single configuration is good in most cases.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;All methods introduces in this work can go beyond the limited application scenario that we reported in the paper. 
Our aim was to introduce a new framework to deal with graphs on a global level, so as to make it possible to study the process underlying a graph-based problem as a whole.&lt;br /&gt;
The proposed techniques are modular and fairly generic: the adversarially regularized graph AE can be used to map graphs on CCMs for other tasks, and the embedding technique for CCMs can be used with other autoencoders and other data distributions. The change detection tests are a bit more specific, but represent a nice application of our new framework on relevant use cases.&lt;/p&gt;

&lt;p&gt;We’re already working on new applications of this framework, to showcase what we believe to be a great potential, so stay tuned!&lt;/p&gt;

&lt;h2 id=&quot;credits&quot;&gt;Credits&lt;/h2&gt;

&lt;p&gt;Code for replicating our experiments will be published on &lt;a href=&quot;https://github.com/danielegrattarola&quot;&gt;my Github&lt;/a&gt;
soon.&lt;br /&gt;
If you wish to cite this work, you can refer to the Arxiv preprint for now:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@article{grattarola2018learning,
  title={Learning Graph Embeddings on Constant-Curvature Manifolds for Change Detection in Graph Streams},
  author={Grattarola, Daniele and Zambon, Daniele and Alippi, Cesare and Livi, Lorenzo},
  journal={arXiv preprint arXiv:1805.06299},
  year={2018}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 07 Jun 2018 00:00:00 +0200</pubDate>
        
        <link>/posts/2018-06-07/ccm-paper.html</link>
          
        
            <category>AI</category>
        
            <category>tutorial</category>
        
          
        
            <category>posts</category>
        
          
      </item>
    
    <item>
        <title>Machine Learning Team Projects: a Survival Guide</title>
        <description>&lt;p&gt;&lt;img src=&quot;http://localhost:4000/images/2018-03-20/cover.jpg&quot; alt=&quot;Training a neural network&quot; class=&quot;full-width&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ever since I started getting closer to machine learning, well before I started my PhD, I have always found it extremely annoying to keep track of experiments, parameters, and minor variations of code that may or may not be of utmost importance to the success of your project.&lt;br /&gt;
This gets incredibly uglier as you wander into uncharted territory, when best practices start to fail you (or have never been defined at all) and the amount of details to keep in mind becomes quickly overwhelming.&lt;br /&gt;
However, nothing increases the entropy of a project like introducing new people into the equation, each one with a different skillset, coding style, and amount of experience.&lt;/p&gt;

&lt;p&gt;In this post I’ll try to sum up some of the problems that I have encountered when doing ML projects in teams (both for research and competitions), and some of the things that have helped me make my life easier when working on a ML project in general.&lt;br /&gt;
&lt;!--more--&gt;
Some of these require people to drop their ancient, stone-engraved practices and beliefs: they will hate you for enforcing change, but after a while you’ll all be laughing back at when Bob used to store 40GB of &lt;code class=&quot;highlighter-rouge&quot;&gt;.csv&lt;/code&gt; datasets on a Telegram chat.&lt;/p&gt;

&lt;p&gt;The three main areas that I’ll cover are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How to deal with code, so that anyone will be able to reproduce the stuff you did and (this is a crazy one) &lt;em&gt;understand what you did by looking at the code&lt;/em&gt;;&lt;/li&gt;
  &lt;li&gt;How to deal with data, so that good ol’ Bob will not only stop using Telegram as a storage server, but will also stop storing data in that obscure standard from 1997;&lt;/li&gt;
  &lt;li&gt;How to deal with logs, so that every piece of information needed to replicate an experiment will be stored somewhere, and you won’t need to run a mental Git tree to remember every little change that the project underwent in the previous 6 months.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;

&lt;p&gt;In this post I’ll be mostly talking about Python.&lt;br /&gt;
That’s because 99% of the ML projects I’ve worked on have been in Python, and the remaining 1% is what Rule 1 of this section is about. I’ll try to keep it as general as possible, but in the end I’m a simple ML PhD student who goes with the trend, so Python it is.&lt;br /&gt;
Let’s start from two basic rules (which, I assure you, have been made necessary by experience):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Use a single programming language&lt;/strong&gt;&lt;br /&gt;
Your team members may come from different backgrounds, have different skills, and different degrees of experience. This can become particularly problematic when coding for a project, as people will try to stick to the languages they know best (usually the ones they used during their education) because they rightfully feel that their performance may suffer from using a different language.&lt;br /&gt;
Democratically deciding on which language to use may be a hard task, but you must never be tempted to tolerate a mixed codebase if you are serious about being a team.&lt;br /&gt;
Eventually, someone might have to put their fist down and resort to threat: don’t push that &lt;code class=&quot;highlighter-rouge&quot;&gt;.r&lt;/code&gt; file on my Python repo ever again if you wish to live.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Everybody must be using the same version of everything&lt;/strong&gt; &lt;br /&gt;
This should be pretty obvious, but I’ve witnessed precious hours being thrown to the wind because OpenAI’s &lt;code class=&quot;highlighter-rouge&quot;&gt;gym&lt;/code&gt; (just to name one) was changed in the backend between versions and nobody had a clue why the algorithms were running differently on different machines. &lt;br /&gt;
Another undesirable situation may present itself when integrating existing codebases written in different versions of the same language. This is obviously more relevant with Python 2/3, where the code is backwards compatible enough between versions for the integration to go smoothly, but &lt;code class=&quot;highlighter-rouge&quot;&gt;2/3&lt;/code&gt; is sneakily equal to 0 in Python 2 and 0.66 in Python 3 (and this may not always be apparent immediately).&lt;/p&gt;

&lt;p&gt;To make it short:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;check your Pythons.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install -U&lt;/code&gt; at least once a week (or never at all until you’re done).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Going a bit more in depth into the realm of crap that one may find oneself in, even once you’re sure that everyone is synced on the basics, there are some additional rules that can greatly improve the overall project experience and will prepare you for more advanced situations in any team project.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Write documentation for at least input and output&lt;/strong&gt;&lt;br /&gt;
You have to work with the sacred knowledge that people may not want to read your code.&lt;br /&gt;
Good documentation is the obvious way to avoid most issues when it comes to working on a team project, but codebases tend to get really big and deadlines tend to get really close, so it may not always be possible to spend time documenting in detail every function. &lt;br /&gt;
A simple trade-off for the sake of sanity is to limit documentation to a single sentence describing what functions do, but clearly describing what are the expected input and output formats. A big plus here is to perform runtime checks, and fail early when the inputs are wrong.&lt;br /&gt;
For instance, one could do something like this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; Does a thing.
	:param a: np.ndarray of shape (n_samples, n_channels); the data to be processed.
	:param b: None or int; the amount of this in that (if None, it will be inferred).

	:return: np.ndarray of shape (n_samples, n_channels + b); the result.
	&quot;&quot;&quot;&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Expected rank 2 array, got rank {}'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;TypeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b should be int or None'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;4. &lt;code class=&quot;highlighter-rouge&quot;&gt;git branch &amp;amp;&amp;amp; git gud&lt;/code&gt;&lt;/strong&gt;&lt;br /&gt;
This is actually a good general practice that should be applied in any coding project.&lt;br /&gt;
Do not test stuff on &lt;code class=&quot;highlighter-rouge&quot;&gt;master&lt;/code&gt;, learn to use the tools of the trade, and read the &lt;a href=&quot;https://www.git-tower.com/blog/git-cheat-sheet/&quot;&gt;Git cheat-sheet&lt;/a&gt;.&lt;br /&gt;
Do not be afraid to create a branch to test a small idea (fortunately they come cheap), and your teammates will appreciate you for not messing up the codebase.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5. Stick to one programming paradigm and style&lt;/strong&gt;&lt;br /&gt;
This may be the hardest rule of all, especially because it’s fairly generic. 
It’s difficult to formalize this rule properly, so here are some examples:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;write PEP8 compliant code (or the PEP8 equivalent for other languages);&lt;/li&gt;
  &lt;li&gt;don’t use single letters for variables that have a specific semantic meaning (e.g. don’t use &lt;code class=&quot;highlighter-rouge&quot;&gt;W&lt;/code&gt; when you can use &lt;code class=&quot;highlighter-rouge&quot;&gt;weights&lt;/code&gt;);&lt;/li&gt;
  &lt;li&gt;keep function signatures coherent;&lt;/li&gt;
  &lt;li&gt;don’t write cryptic one-liners to show off your power level;&lt;/li&gt;
  &lt;li&gt;don’t use a &lt;code class=&quot;highlighter-rouge&quot;&gt;for&lt;/code&gt; cycle if everything else is vectorized;&lt;/li&gt;
  &lt;li&gt;don’t define classes if everything else is done with functions in modules (e.g. don’t create a &lt;code class=&quot;highlighter-rouge&quot;&gt;Logger&lt;/code&gt; class that exposes a &lt;code class=&quot;highlighter-rouge&quot;&gt;log()&lt;/code&gt; method, but create a &lt;code class=&quot;highlighter-rouge&quot;&gt;logging.py&lt;/code&gt; module and &lt;code class=&quot;highlighter-rouge&quot;&gt;import log&lt;/code&gt; from it);&lt;/li&gt;
  &lt;li&gt;don’t use sparse matrices if everything else is dense (unless absolutely necessary, and always remember Rule 3 anyway).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I realize this is all a bit vague, so I’ll just summarize it as “stick to the plan” and shamelessly leave you to learn from experience.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;6. Don’t add a dependency if you’ll only use it once&lt;/strong&gt;&lt;br /&gt;
This could have actually been an example of Rule 6, but I’ve seen too many atrocities in this regard to not make it into a rule.&lt;br /&gt;
Sometimes it will be absolutely tempting to use a library with which you have experience to do a single task, and you will want to import that library “just this once” to get done with it.&lt;br /&gt;
This quickly leads to &lt;a href=&quot;https://en.wikipedia.org/wiki/Dependency_hell&quot;&gt;dependency hell&lt;/a&gt; and puts Rule 2 in danger, so try to avoid it at all costs. &lt;br /&gt;
Examples of this include using Pandas because you are not confident enough with Numpy’s slicing, or importing Seaborn because Matplotlib will require some grinding, or copy-pasting that two-LOC solution from StackOverflow.&lt;br /&gt;
Of course, this is gray territory and you should proceed with common sense: sometimes it’s really useless to reinvent the wheel, in which case you can &lt;code class=&quot;highlighter-rouge&quot;&gt;import&lt;/code&gt; away without guilt, but most times a quick Google search will provide you with native solutions within the existing requirements of the project.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;7. Comment non-trivial code, but do not over-commit to the cause&lt;/strong&gt;&lt;br /&gt;
Comments should be a central element of any codebase, because they are the most effective way of allowing others (especially the less skilled) to understand what you did; they are the only ones that can save your code’s understandability should Rule 5 come less.&lt;br /&gt;
Especially in ML projects, where complex ideas may lead to complex architectures, and most stuff is usually vectorized (i.e. ugly, ugly code may happen more frequently than not), leaving a good trail of comments behind you may be crucial for the sake of the project, especially when you find yourself debugging a piece of code that was written six months before.&lt;br /&gt;
At the same time, you should avoid commenting every single line of code that you write, in order to keep the code as tidy as possible, reduce redundancy, and improve readability.&lt;br /&gt;
So for instance, a good comment would be:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# Compute the model's output as WX + b&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;where the information conveyed is as minimal and as exact as possible (maybe this specific example shouldn’t even require a comment, but you get the idea). Note that in this case the comment refers to variables by other names: this is not necessarily a good practice, but I find it helpful to link what you are doing in the code with what you did in the associated paper.&lt;br /&gt;
On the other hand, a comment like the following (actually found in the wild):&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Set the model's flag to freeze the weights and prevent training&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;should be avoided at all costs. But you knew that already.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;data&quot;&gt;Data&lt;/h2&gt;

&lt;p&gt;Data management is a field that is so vast and so complex that it’s basically impossible for laymen (such as myself) to do a comprehensive review of the best practices and tools.&lt;br /&gt;
Here I’ll try to give a few pointers that are available to anyone with basic command line and programming knowledge, as well as some low-hassle tricks to simplify the life of the team.&lt;br /&gt;
You should probably note, as a disclaimer, that I’ve never worked with anything bigger than 50GB, so there’s that. But anyway, here we go.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Standardize and modernize data formats&lt;/strong&gt;&lt;br /&gt;
Yes, I know. I know that in 1995, IEEE published an extremely well defined standard to encode an incredibly specific type of information, and that this is exactly the type of data that we’re using right now.
And I know that XML was the semantic language of the future, in 2004.
I know that you searched the entire Internet for that dataset, and that the Internet only gave you a &lt;code class=&quot;highlighter-rouge&quot;&gt;.mat&lt;/code&gt; file in return.&lt;br /&gt;
But, this is what we should do instead:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;use &lt;code class=&quot;highlighter-rouge&quot;&gt;.npz&lt;/code&gt; for matrices;&lt;/li&gt;
  &lt;li&gt;use &lt;code class=&quot;highlighter-rouge&quot;&gt;.json&lt;/code&gt; for structured data;&lt;/li&gt;
  &lt;li&gt;use &lt;code class=&quot;highlighter-rouge&quot;&gt;.csv&lt;/code&gt; for classic relational data (e.g. the Iris dataset, stuff with well defined categories);&lt;/li&gt;
  &lt;li&gt;serialize everything else with libraries like Pickle or H5py.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Keep it as simple, as standard, and as modern as possible.&lt;br /&gt;
And remember: it’s better to convert data once, and then read from the chosen standard format, rather than converting at runtime, every time.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Drop the Dropbox&lt;/strong&gt; &lt;br /&gt;
Dropbox and Google Drive are consumer-oriented platforms that are specifically designed to help the average user have a simple and effective experience with cloud storage. They surely can be used as backend for more technical situations through the use of command line, but in the end they will bring you down to integration hell and keep you there forever.&lt;br /&gt;
Here’s a short list of tools and tips for cloud storage and data handling that I have used in the past as alternative to the big D (no pun intended).&lt;/p&gt;

&lt;p&gt;Data storage:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Set up a centralized server (as you most likely do anyway to run heavy computations) and keep everything there;&lt;/li&gt;
  &lt;li&gt;Set up and S3 bucket and add a &lt;code class=&quot;highlighter-rouge&quot;&gt;dataset_downloader.py&lt;/code&gt; to your code;&lt;/li&gt;
  &lt;li&gt;Set up a NAS (good for offices, less for remote development);&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Data transfers:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Use the amazing &lt;a href=&quot;https://transfer.sh&quot;&gt;transfer.sh&lt;/a&gt;, a free service that allows you to upload and download files up to 10GB for up to 30 days;&lt;/li&gt;
  &lt;li&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;rsync&lt;/code&gt;;&lt;/li&gt;
  &lt;li&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;sftp&lt;/code&gt;;&lt;/li&gt;
  &lt;li&gt;Use Filezilla or equivalent &lt;code class=&quot;highlighter-rouge&quot;&gt;sftp&lt;/code&gt; clients.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;3. Don’t use Git to move source files between machines&lt;/strong&gt;&lt;br /&gt;
This is once again an extension of the previous rule.&lt;br /&gt;
The situation is the following: you’re debugging a script, testing out hyperparameters, or developing a new feature of your architecture. You need to run the microscopically different script on the department’s server, because your laptop can’t deal with it. You &lt;code class=&quot;highlighter-rouge&quot;&gt;git commit -m 'fix' &amp;amp;&amp;amp; git push origin master&lt;/code&gt;. Linus Torvalds dies (and also you broke Rule 4 of the coding section).&lt;br /&gt;
Quick fix: keep a &lt;code class=&quot;highlighter-rouge&quot;&gt;sftp&lt;/code&gt; session open and &lt;code class=&quot;highlighter-rouge&quot;&gt;put&lt;/code&gt; the script, instead. Once you’re sure that the code works, then you can roll back the changes on the remote machine, commit from the local machine just once, and then pull on the remote to finish.&lt;/p&gt;

&lt;p&gt;This will make life easier for someone who has to roll back the code or browse commits for any other reason, because they won’t have to guess which one of the ten ‘fix’ commits is the right one.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. Don’t push data to Github&lt;/strong&gt;&lt;br /&gt;
On a similar note, avoid using Github to keep track of your data, especially if the data is subject to frequent changes. Github will block you if you surpass a certain file size, but in general this is a solution that doesn’t scale.&lt;br /&gt;
There is one exception to this rule: small, public benchmark datasets. Those are fine and may help people to reproduce your work by conveniently providing them with a working OOB environment, but everything else should be handled properly.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5. Test small, run big&lt;/strong&gt; &lt;br /&gt;
Keep a small subset of your data on your development machine, big enough to cover all possible use cases (e.g. train/test splits or cross validation), but small enough to keep your runtimes in the order of seconds.&lt;br /&gt;
Once you’re ready to run experiments for good, you can use the whole dataset and leave the machine to do its work.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;p&gt;Experiment, runs, call them however you like. It’s the act of taking a piece of code that implements a learning algorithm, throw data at it, get information in return.&lt;br /&gt;
I’ve wasted long hours trying to come up with the perfect Excel sheet to keep track of every nuance of my experiments, only to realize that it’s basically impossible to do so effectively.&lt;br /&gt;
In the end, I’ve found that the best solutions are to either have your script output a dedicated folder for each run, or have an old school paper notebook on which you record your methodology as you would take notes in class. Since the latter is more time consuming and personal, I’ll focus on the former.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Keep hyperparameters together and logged&lt;/strong&gt;&lt;br /&gt;
By my very own, extremely informal definition, hyperparameters are those things that you have to pick by hand (or cross-validation) and that will FUCK! YOU! UP! whenever they feel like it. You might think that the success of your paper depends on your hard work, but it really doesn’t: it’s how you pick hyperparameters.&lt;br /&gt;
But asides aside, you really should keep track of the hyperparameters for every experiment that you run, for two simple reasons:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;They will be there when you need to replicate results or publish your code with the best defaults;&lt;/li&gt;
  &lt;li&gt;They will be there when you need to write the Experiments section of the paper, so you will be sure that result A corresponds to hyperparameters set B, without having to rely on your source code to keep track of hyperparameters for you.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In general, it’s also a good idea to log every possible choice and assumption that you have to make for an experiment, and that includes also meta-information like what optimization algorithm or loss you used in the run.&lt;/p&gt;

&lt;p&gt;By logging everything properly, you’ll ensure that every team member will know where to look for information, ad they will not need to assume anything else other than what is written in the logs.&lt;/p&gt;

&lt;p&gt;A cool code snippet that I like to run after the prologue of every script is the following (taken from my current project):&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Defined somewhere at some point&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;global&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LOGFILE&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endswith&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LOGFILE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LOGFILE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Define all hyperparameters here&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# ...&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Log hyperparameters&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__file__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vars_to_log&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'SEED'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'latent_space'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'learning_rate'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'beta_1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'epochs'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
	       &lt;span class=&quot;s&quot;&gt;'batch_size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'es_patience'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'classes'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'optimizer'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'loss'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vars_string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Setting:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vars_to_log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vars_string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'- {}: {}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vars_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;which will give you a neat and tidy:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/path/to/file/run.py
Setting: 
- SEED: 1337 
- latent_space: 128 
- learning_rate: 1e-3
- beta_1: 0.99
- epochs: 100 
- batch_size: 32 
- es_patience: 10
- classes: 2
- optimizer: 'adam' 
- loss: 'binary_crossentropy'		   
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;2. Log architectural details&lt;/strong&gt; &lt;br /&gt;
This one is an extension of Rule 1, but I just wanted to show off this extremely useful function to convert a Keras model to a string:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model_to_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;to_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;model_to_str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model_to_str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;print_fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_to_str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Keep track of how your model is structured, and save this information for every experiment so that you will be able to remember changes in time.&lt;br /&gt;
Sometimes, I’ve seen people copy-pasting entire scripts in the output folder of an experiment in order to remember what architecture they used: don’t.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Plots before logs&lt;/strong&gt;&lt;br /&gt;
We do science to show our findings to the world, the other members of our team, or at the very least to our bosses and supervisors.&lt;br /&gt;
This means that the best results that you may obtain in a project instantly lose their value if you cannot communicate properly what you found, and in 2018 that means that you have to learn how to use data visualization techniques. &lt;br /&gt;
&lt;a href=&quot;https://www.amazon.com/Visual-Display-Quantitative-Information/&quot;&gt;Books&lt;/a&gt; have been written on the subject, so I won’t go into details here. 
Just remember that a good visualization always trumps a series of unfriendly floats floating around.&lt;br /&gt;
Some general tips on how to do data viz:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;label your axes;&lt;/li&gt;
  &lt;li&gt;don’t be scared of 3D plots;&lt;/li&gt;
  &lt;li&gt;time is a powerful dimension that should always be taken into consideration: create animated plots whenever possible (use &lt;code class=&quot;highlighter-rouge&quot;&gt;matplotlib.animation&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;imageio&lt;/code&gt; to create gifs in Python);&lt;/li&gt;
  &lt;li&gt;if you have an important metric of interest (e.g. best accuracy) and you’ve already saturated your plot’s dimensions, print it somewhere on the plot rather than storing it in a separate file.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;4. Keep different experiments in different scripts&lt;/strong&gt;&lt;br /&gt;
This should probably go in the Code section of this post, but I’ll put it here as it relates more to experiments than to code.&lt;br /&gt;
Even with Rules 1 and 2 accounted for, sometimes you will have to make changes that are difficult to log. 
In this case, I find it a lot more helpful to clone the current script (or create a new branch) and implement all variations on the new file.&lt;br /&gt;
This will prevent things like “&quot;”temporarily””” hardcoding stuff to quickly test out a new idea, or having &lt;code class=&quot;highlighter-rouge&quot;&gt;if&lt;/code&gt; statements in every other code block to account for the two different methodologies, and it will only add a bit of overhead to your development time.&lt;br /&gt;
The only downside of this rule is that sometimes you’ll find a bug or implement a cool plot in the new script, and then you’ll have to sync the old file with the new one. However, editors like PyCharm make it easy to keep files synced: just select the two scripts and hit &lt;code class=&quot;highlighter-rouge&quot;&gt;ctrl + d&lt;/code&gt; to open the split-view editor which conveniently highlights the differences and lets you move the code around easily.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;This is far from a complete guide (probably far from a guide at all), and i realize that some of the rules are not even related to working in teams. I just wanted to put together a small set of practices that I picked up from people way more skilled than me, in the hope of making collaborations easier, simplifying the workflow of other fellow PhD students that are just beginning to work with code seriously, and eventually, hopefully, leading to a more standardized way of publishing ML research in the sake of reproducibility and democratization.&lt;br /&gt;
I am sure that many people will know better, smarter, more common practices that I am unaware of, so please do &lt;a href=&quot;https://danielegrattarola.github.io/about/&quot;&gt;contact me&lt;/a&gt; if you want to share some of your knowledge.&lt;/p&gt;

&lt;p&gt;Cheers&lt;/p&gt;
</description>
        <pubDate>Tue, 20 Mar 2018 00:00:00 +0100</pubDate>
        
        <link>/posts/2018-03-20/ml-team-projects.html</link>
          
        
            <category>code</category>
        
            <category>tutorial</category>
        
          
        
            <category>posts</category>
        
          
      </item>
    
    <item>
        <title>Overthinking Japan</title>
        <description>&lt;p&gt;&lt;img src=&quot;http://localhost:4000/images/2017-10-31/shinjuku.jpeg&quot; alt=&quot;Piss Alley in Shinjuku, Tokyo (ph. Daniele Grattarola)&quot; class=&quot;full-width&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I went to Japan with the expectation of finding a culture perfectly balanced 
between the immovable certainty of the past and the unforgiving, unstoppable
forward pull of the future. These are, after all, the two forces that I find myself subject to every day of my life: a hard, consolidated core of ground beliefs and values (like family, loyalty, tradition), and a constant attraction towards the bleeding edge, the unknown, the new.&lt;/p&gt;

&lt;p&gt;I won’t hide, however, that there are other reasons for which this unique country exercises a heavy charisma over me, reasons that I think can be easily shared by many other people of my generation.&lt;br /&gt;
&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;For one, childhood. I grew up with a substantial percentage of my entertainment, and by extension the center of mass around which my happiness gravitated (read: the games that I played as a kid), coming from Japan.&lt;br /&gt;
Cartoons, comic books, games, video games: Japanese, or Japanese representations of the western world. 
It’s not a mystery that in times of uncertainty, or difficulty, we turn to the past to seek happiness, and I think that even for someone with a healthy and (semi) successful life there are factors for which this mechanism could become relevant. The constant competition of your peers, the &lt;a href=&quot;https://ribbonfarm.com/2017/08/17/the-premium-mediocre-life-of-maya-millenial/&quot;&gt;premium mediocrity&lt;/a&gt; of our millenial lives, the melting economic glacier: all potential reasons for which one could want to look back, rather than ahead. 
This does not mean that I consciously weighted this aspect when planning my trip, but it could explain a bias when I spun the globe and pointed to the destination for a self-searching, once-in-a-lifetime solo travel after graduation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/images/2017-10-31/osaka.jpeg&quot; alt=&quot;Osaka seen from the Tsutenkaku tower (ph. Daniele Grattarola)&quot; class=&quot;full-width&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And another important component of this bias is, unsurprisingly, the Internet. 
I don’t mean the internet of social media, forums, “AI” journalism, and porn. I mean the Internet as an entity, with a capital “I”. The omnipotent and omniscient God of the Internet Kvlt, the powerful, unaccessible aesthetical phenomenon at the center of Vaporwave, the enabling technology of cyberpunk, the tyrant freedom and freeing tyranny of our lives. It’s that thing that you can’t explain to your parents when they ask you why memes are a thing.&lt;br /&gt;
The blast of the Internet was heavily fueled by Japanese culture and aesthetics, and we, as a collective, elected Japan as the physical embodiment of our intangible universe of information.&lt;br /&gt;
There are interesting and complex aspects to this, because while Japan was being brought forth as the de facto land of the Internet, Japanese millenials were diving deeper and deeper into the Internet culture, tumbling in a downward (or upward) spiral until the country became the conceptual caricature of itself, an entity that doesn’t need to stress its characteristics in order to make them evident, because it already managed to erase the barrier between reality and its representation. If you think about it, this is the same exact phenomenon that characterizes the Internet (again, capital “I”), where information transcends the real world and becomes meta-information. 
And I find in this meta-information, in the post-post-post-ironic memes, in monospaced fonts, classic statues over pink backgrounds, 80’s aesthetics, 8-bit music, and glitch art the most fascinating cultural movement of our time.&lt;/p&gt;

&lt;p&gt;Given these (at least two) sources of bias in my choice, I booked a flight and headed to Japan.&lt;br /&gt;
As expected, it was exactly what I thought it would be. But it was even more.&lt;/p&gt;

&lt;p&gt;When walking alone in the forests, the firework-like cities, or the wooden temples from which you could see all the way down to your Self, I was humming the mono themes from Pokemon Gold because that’s where my mind would go more often than not. I found myself spending six hours in Akihabara mesmerized by the otaku culture even if I don’t even watch anime anymore (if I ever did at all). I almost cried at the neon covered buildings because there I realized that cyberpunk aesthetic is real, and that I was there to witness it. The barrier between reality and its representation in my mind shattered, as if by being there I became part of the meta-universe myself.&lt;br /&gt;
A big part of what enabled this to happen is the almost constant solitude in which I lived for 15 days, with a linguistic barrier there to isolate me even from the passive communication around me and facilitating the deconstruction of reality which was going on in my mind.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/images/2017-10-31/buddha.jpeg&quot; alt=&quot;Golden Buddha in Shitenno-ji temple, Osaka (ph. Daniele Grattarola)&quot; class=&quot;full-width&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Then there was the introspection, because you can’t help but think about your existence when you find yourself staring at a ten meter golden Buddha who, in turn, stares back at you with a mystical power so strong that the statue itself seems to be alive. And in those moments, armed with a few simple spiritual axioms that I picked up over the years, I could make sense of religion as a whole, not by embracing it, but by tearing it apart and understanding the mechanism underneath, with the same level of comprehension that you would get by opening up a clock and seeing the cogs, rather than simply using it to read the time (or, for me, seeing other people using it, as luckily I never felt the need of an outside force to explain my unknowns).&lt;br /&gt;
By looking past the religious wall, I could then easily navigate philosophy (again, armed of a few authors that I have in my cultural baggage) and try to make sense of existence, or what derives thereof (&lt;a href=&quot;http://exsubstantia.com/about&quot;&gt;ex substantia&lt;/a&gt;), because only in those specific situations the Search could yield results.&lt;br /&gt;
This last level is what, for me, completed the unification, what finally removed the Veil of Maya and made me experience the metaphysical through the senses, and in turn explained the aristotelian Act by deconstructing the Potency, by stepping into Plato’s cave and forcing the true concepts to come out to the world.&lt;/p&gt;

&lt;p&gt;Eventually, what this trip meant for me was a step forward to a view of existence in which all barriers between the real and the conceptualized are pointless, where either can be used to convey meaning to one’s life and where substance (i.e. the true essence of things) can be found in either.&lt;/p&gt;

&lt;p&gt;Besides overthinking, however, getting to know a different culture was amazing, the food was mind-blowing, I met amazing people, and learning Japanese is being lots of fun. I feel like I’m now ready to start a new adventure, like this trip was the perfect full stop to my first chapter and the start of a new one, in which I will test myself in the international arena of research and maybe, hopefully, leave a trace in the advances of humanity.&lt;/p&gt;

&lt;p&gt;I warmly suggest you to check out &lt;a href=&quot;https://insidekyoto.com&quot;&gt;Inside Kyoto&lt;/a&gt; to get around Japan, it made the whole trip a lot more enjoyable for me.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/images/2017-10-31/bridge.jpeg&quot; alt=&quot;Shinkyo brigde, Nikko (ph. Daniele Grattarola)&quot; class=&quot;full-width&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 31 Oct 2017 00:00:00 +0100</pubDate>
        
        <link>/posts/2017-10-31/overthinking-japan.html</link>
          
        
            <category>travel</category>
        
            <category>philosophy</category>
        
          
        
            <category>posts</category>
        
          
      </item>
    
    <item>
        <title>The Fermi Paradox of Superintelligence</title>
        <description>&lt;p&gt;&lt;img src=&quot;http://localhost:4000/images/2017-09-25/seti.jpg&quot; alt=&quot;The Allen Telescope Array (Public domain)&quot; class=&quot;full-width&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Attirbuted to Enrico Fermi as a back-of-the-envelope astrobiological philosphy 
exercise, Fermi’s paradox is a simply put question: &lt;em&gt;where is everybody?&lt;/em&gt;&lt;br /&gt;
In other words, if life is a truly common phenomenon in the universe, then
the probability of a civilization solving the problem of interstellar travel
should be pretty high, and the effects of such a civilization on the galaxy 
should be extremely evident to an observer (think entire stars being instantly 
harvested for power).&lt;br /&gt;
However, the SETI remains unsuccessful, hence where is everyone? 
&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://scholar.google.it/scholar?q=fermi+paradox&quot;&gt;A quick search on Scholar&lt;/a&gt;
will give you literally thousands of reasons not to panic (or maybe do the
opposite, depending on how much you like aliens), and provide you with many
logical reasons why the presence of ETI could go unnoticed, leaving us in our
quiet and lonely neighborhood.&lt;br /&gt;
Having sorted that out, we can safely go back to our Twitter feeds to discuss
&lt;a href=&quot;https://twitter.com/dog_rates/status/775410014383026176&quot;&gt;serious business&lt;/a&gt; 
and &lt;a href=&quot;https://www.theguardian.com/technology/2017/aug/14/elon-musk-ai-vastly-more-risky-north-korea&quot;&gt;Elon Musk’s latest views on AI&lt;/a&gt;.&lt;br /&gt;
We can also go back to our comfy evening reads, which in my case mean Hofstader’s
&lt;em&gt;GEB&lt;/em&gt; (for the sixth time or so) and Nick Bostrom’s &lt;em&gt;Superintelligence&lt;/em&gt;, 
while listening to the sound of the falling rain.
And then, when the words are stirring inside your head, and the rain has
flushed the world clean, and the only sound you can hear is the quiet whir
of the GPU fan, while it’s training that 10-layer net that you’ve been recently
working on; only then, you might find yourself asking the question: &lt;em&gt;where the hell is superintelligence?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;That’s a reasonable question, isn’t it? Just look at all the informed opinions 
of the better, wiser people than me that I cited above on the subject. 
They may disagree on its nature, but no one (&lt;em&gt;no one&lt;/em&gt;) disagrees that AGI will 
have an almost infinite growth rate.&lt;br /&gt;
Go back to the second sentence of this post, and replace “interstellar travel”
with “artificial intelligence” to have an idea of what that may look like. 
And we’re not talking of a simple Kardashev scale boost; a superintelligence would
be well aware of its physical limitations, so we would likely be looking at an
end-of-the-galaxy scenario, with all available matter being converted to 
computing infrastructure, &lt;em&gt;à la&lt;/em&gt; Charles Stross.&lt;/p&gt;

&lt;p&gt;A phenomenon so powerful that its mere exisistence would change the scale of 
reference for every other phenomena in the universe, something so good at self
imporving that it would only be limited by physical laws.&lt;/p&gt;

&lt;p&gt;If the probability of life in the universe is high, then so is the probability
of a civilization developing a superintelligence, with all its extremely evident
effects.&lt;br /&gt;
So where is it?&lt;/p&gt;

&lt;p&gt;So far, I only talked about a catastrophic scenario following the creation of a
superintelligence, but we have to consider the postive and neutral outcomes, 
before denying the existence of a super AI.&lt;/p&gt;

&lt;p&gt;If the effects of a superintelligence on its universe were not so devastating, 
if we look at the brightest end of the spectrum of possibility, think about the 
advances that such an entity would bring to its creators. All the technologically
motivated solutions to the Fermi paradox, at that point, would be null, leaving
us with a whole lot less formal analysis, and a whole lot more speculation on
alien sociology and superintelligent motives.&lt;br /&gt;
What reason could a civilization with a superintelligence in its toolbox have 
to not reach out of its planet?&lt;/p&gt;

&lt;p&gt;Moreover, we couldn’t still exclude a catastrophic end of the galaxy, if the 
computational necessities of the AI required it to favor an absolute good
(its existence) to a relative one (our existence).
Therefore, if we allow for a truly &lt;em&gt;good&lt;/em&gt; superintelligence to exist somewhere
in the universe right now, we have to imagine natural, moral, or logical 
impediments that prevent it from communicating outwards and spreading infinite 
progress.&lt;/p&gt;

&lt;p&gt;From another perspective, even if talking about &lt;em&gt;likelihood&lt;/em&gt; in this context 
is a serious gnoseological gamble, it seems that the neutral scenarios would 
likely be the less noticeable: superintelligence is there, but it has no drive 
to manifest itself.&lt;br /&gt;
That could either be for a lack of necessity (it wouldn’t need energy, or matter, 
or information), or a lack of advantage (it wouldn’t want to reveal its presence
to avoid danger, or to avoid pointless expenses of limited resources), and it 
would be a fairly easy and rational explanation to the superintelligence paradox.&lt;br /&gt;
A system in such a perfect equilibrium would probably exist in a super-state, 
free from the unforgiving grip of entropy and eternally undetected (short of
using another superintelligence, at which point the paradox would already be
solved).&lt;/p&gt;

&lt;p&gt;I stop here with the examples, because it’s out of my capabilities to summarize
all possible scenarios, especially when we consider that the Fermi paradox has 
inspired fifty years of debate. 
And if we think about this debate, we see that it extends back in the ages, 
that “alien civilization”, “AI”, or “God” have been used interchangeably without
 changing the essence of the discourse: why, if &lt;em&gt;they&lt;/em&gt; exist, are they not 
 manifest?&lt;/p&gt;

&lt;p&gt;As hard as we try to rationalize this question, we perfectly know that there
are only two possible outcomes, that we are looking for a black swan that we will
either find, or keep looking for. At the same time, we’ve learned very well 
how to coexist with this uncertainty, because we only need the possibility of a
forced ignorance, in order to accept an ignorance undesired.&lt;/p&gt;

&lt;p&gt;And so, as men of rational intellects we can be crushed by the lack of knowledge, 
or be incessantly driven by it, knowing that every second spent in the search 
is a second that could have only be wasted otherwise. And those who are crushed, 
may turn to faith, and find peace in knowing that their happiness resides with 
the black swan, where it can’t be touched by mortal sight.&lt;/p&gt;

&lt;p&gt;In the end, while telling us a lot about human condition, this thought leaves
us back in our quiet neighborhood of probable but unverifiable truths.&lt;br /&gt;
However, when considering the practically null amout of time that constitutes our
lives, a question may come to one’s mind: is it closer to human nature to 
think of a God, or to seek one out?&lt;/p&gt;

</description>
        <pubDate>Mon, 25 Sep 2017 00:00:00 +0200</pubDate>
        
        <link>/posts/2017-09-25/fermi-paradox-ai.html</link>
          
        
            <category>AI</category>
        
          
        
            <category>posts</category>
        
          
      </item>
    
    <item>
        <title>New Blog</title>
        <description>&lt;p&gt;&lt;img src=&quot;http://localhost:4000/images/header/oz.jpg&quot; alt=&quot;Australian Outback (ph. Daniele Grattarola)&quot; class=&quot;full-width&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This blog is an updated version of my old edgy, teenage-years blog at &lt;a href=&quot;http://exsubstantia.com&quot;&gt;exsubstantia.com&lt;/a&gt;.
I kept a somewhat similar style because I like the way Exsubstantia looks, but I hope that the difference in content
will speak for itself.&lt;/p&gt;

&lt;p&gt;I will use this blog to talk mostly about two things:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;interesting concepts that I come across when working on my research and projects&lt;/li&gt;
  &lt;li&gt;interesting stuff that I come across when traveling around&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;but I’ll try to keep it varied, and also talk about other interesting things. 
I will try to include code whenever necessary, but for more complex projects you can check out &lt;a href=&quot;https://github.com/danielegrattarola&quot;&gt;my Github&lt;/a&gt;.
You can also find me on &lt;a href=&quot;https://twitter.com/riceasphait&quot;&gt;Twitter&lt;/a&gt; and &lt;a href=&quot;https://www.instagram.com/riceasphait/&quot;&gt;Instagram&lt;/a&gt; as @riceasphait.&lt;/p&gt;

&lt;p&gt;Cheers!&lt;/p&gt;
</description>
        <pubDate>Tue, 19 Sep 2017 00:00:00 +0200</pubDate>
        
        <link>/posts/2017-09-19/new-blog.html</link>
          
        
            <category>update</category>
        
          
        
            <category>posts</category>
        
          
      </item>
    
  </channel>
</rss>
